{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 3],\n",
      "        [ 1],\n",
      "        [ 9],\n",
      "        [ 5],\n",
      "        [ 2],\n",
      "        [ 9],\n",
      "        [ 5],\n",
      "        [10],\n",
      "        [ 1],\n",
      "        [ 6],\n",
      "        [ 6]]]), [5.7])\n",
      "train data loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# with tf.variable_scope(\"greg\", reuse=True) as scope:\n",
    "#Source code with the blog post at http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow.models.rnn import rnn_cell\n",
    "# from tensorflow.models.rnn import rnn\n",
    "\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "# train_input = ['{0:020b}'.format(i) for i in range(2**10)]\n",
    "# shuffle(train_input)\n",
    "# train_input = [map(int,i) for i in train_input]\n",
    "# ti  = []\n",
    "# for i in train_input:\n",
    "#     temp_list = []\n",
    "#     for j in i:\n",
    "#             temp_list.append([j])\n",
    "#     ti.append(np.array(temp_list))\n",
    "# train_input = ti\n",
    "\n",
    "# train_output = []\n",
    "# for i in train_input:\n",
    "#     count = 0\n",
    "#     for j in i:\n",
    "#         if j[0] == 1:\n",
    "#             count+=1\n",
    "#     temp_list = ([0]*21)\n",
    "#     temp_list[count]=1\n",
    "#     train_output.append(temp_list)\n",
    "\n",
    "# test_input = train_input[NUM_EXAMPLES:]  # 24,20\n",
    "# test_output = train_output[NUM_EXAMPLES:] # 24,21 \n",
    "# train_input = train_input[:NUM_EXAMPLES] # 1000,20\n",
    "# train_output = train_output[:NUM_EXAMPLES] # 1000,21\n",
    "\n",
    "def get_batch():\n",
    "    batch = [[]]\n",
    "    total = 0\n",
    "    for i in range(0,11):\n",
    "        x = random.randint(1,10)\n",
    "        batch[0].append([x])\n",
    "        total += x\n",
    "    return np.array(batch), [total*.1]\n",
    "\n",
    "greg = get_batch()\n",
    "\n",
    "print(greg)\n",
    "\n",
    "\n",
    "print('train data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.20132\n",
      "200: 0.195185\n",
      "400: 1.63602\n",
      "600: 0.529652\n",
      "800: 0.0677576\n",
      "1000: 0.0672946\n",
      "1200: 0.607251\n",
      "1400: 1.10967\n",
      "1600: 1.18671\n",
      "1800: 0.926635\n",
      "2000: 0.747303\n",
      "2200: 0.288234\n",
      "2400: 0.892438\n",
      "2600: 0.0340867\n",
      "2800: 0.0112767\n",
      "3000: 0.0523024\n",
      "3200: 0.47391\n",
      "3400: 0.303184\n",
      "3600: 0.113762\n",
      "3800: 0.676772\n",
      "4000: 0.202333\n",
      "4200: 0.151063\n",
      "4400: 0.210973\n",
      "4600: 0.0549126\n",
      "4800: 0.150285\n",
      "5000: 0.00504875\n",
      "5200: 0.365706\n",
      "5400: 0.369738\n",
      "5600: 0.466591\n",
      "5800: 0.25811\n",
      "6000: 0.156282\n",
      "6200: 0.177514\n",
      "6400: 0.524967\n",
      "6600: 0.370193\n",
      "6800: 0.463995\n",
      "7000: 0.117648\n",
      "7200: 0.177372\n",
      "7400: 0.0108557\n",
      "7600: 0.443592\n",
      "7800: 0.403214\n",
      "8000: 0.0800943\n",
      "8200: 0.59173\n",
      "8400: 0.0811105\n",
      "8600: 0.0537829\n",
      "8800: 0.224004\n",
      "9000: 0.194407\n",
      "9200: 0.109201\n",
      "9400: 0.0976195\n",
      "9600: 0.0731497\n",
      "9800: 0.0065403\n",
      "10000: 0.698755\n",
      "10200: 0.173537\n",
      "10400: 0.0516372\n",
      "10600: 0.20481\n",
      "10800: 0.210446\n",
      "11000: 0.278581\n",
      "11200: 0.232893\n",
      "11400: 0.0240502\n",
      "11600: 0.132368\n",
      "11800: 0.0928464\n",
      "12000: 0.285971\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"greg\", reuse=True) as scope:\n",
    "\n",
    "    data = tf.placeholder(tf.float32, [None, 11,1]) #Number of examples, number of input, dimension of each input\n",
    "    target = tf.placeholder(tf.float32, [1])\n",
    "    num_hidden = 11\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "    val, _ = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\n",
    "    \n",
    "#     val = tf.transpose(val, [1, 0, 2])\n",
    "#     last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "    last = val[0,10,:]\n",
    "    lastTotal = tf.reduce_sum(tf.abs(last))\n",
    "    loss = tf.abs(target[0]-lastTotal)\n",
    "#     optimizer = tf.train.AdagradOptimizer(.03)\n",
    "#     optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(.03)\n",
    "    \n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "#     weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "#     bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))\n",
    "#     prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "#     cross_entropy = -tf.reduce_sum(target * tf.log(prediction))\n",
    "#     optimizer = tf.train.AdamOptimizer()\n",
    "#     minimize = optimizer.minimize(cross_entropy)\n",
    "#     mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "#     error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "\n",
    "#     inp, out = train_input[0:1], train_output[0:1]\n",
    "    \n",
    "#     print(inp)\n",
    "    \n",
    "    for i in range(0,15001):\n",
    "        inp = get_batch()\n",
    "        sess.run(train_step,{data:inp[0],target:inp[1]})\n",
    "        if(i%200 ==0):\n",
    "            print(str(i)+': '+str(sess.run(loss,{data:inp[0],target:inp[1]})))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.10094541  0.01640086 -0.14926097  0.08908965]]\n",
      "\n",
      " [[-0.17274372  0.01264222 -0.19872776  0.16348584]]\n",
      "\n",
      " [[-0.17223734 -0.01183535 -0.1075826   0.19914645]]\n",
      "\n",
      " [[-0.18111679 -0.00191544 -0.1540789   0.20453331]]\n",
      "\n",
      " [[-0.18668649 -0.01704033 -0.07527536  0.23238693]]\n",
      "\n",
      " [[-0.12974223 -0.02258761 -0.01482019  0.20044228]]\n",
      "\n",
      " [[-0.08711073 -0.01824811  0.01834305  0.16460145]]\n",
      "\n",
      " [[-0.0563496  -0.00907683  0.03430592  0.13233964]]\n",
      "\n",
      " [[-0.1238291   0.01831533 -0.10888778  0.16055954]]\n",
      "\n",
      " [[-0.12351688  0.00458201 -0.0528673   0.18756996]]]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "inp, out = train_input[0:1], train_output[0:1]\n",
    "print(sess.run(val,{data: inp, target: out}))\n",
    "\n",
    "# batch_size = 100\n",
    "# no_of_batches = int(len(train_input) / batch_size)\n",
    "# print(no_of_batches)\n",
    "# epoch = 50\n",
    "# for i in range(epoch):\n",
    "#     ptr = 0\n",
    "#     for j in range(no_of_batches):\n",
    "#         inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "#         ptr+=batch_size\n",
    "#         sess.run(minimize,{data: inp, target: out})\n",
    "#     print (\"Epoch \"+str(i))\n",
    "# incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "# print(sess.run(prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0],[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]}))\n",
    "# print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
